{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOahaUUH2_r1",
        "outputId": "0c2cdf0b-52fd-4667-e8c1-0bb345cfc889"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cpu\n"
          ]
        }
      ],
      "source": [
        "import torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "import torch.nn as nn\n",
        "from ast import Continue\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchsummary import summary\n",
        "from tqdm import tqdm\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "IxkFAuKC3ggP"
      },
      "outputs": [],
      "source": [
        "#mnist = torchvision.datasets.MNIST(root = './data/',download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOOVIpUlm8Oj",
        "outputId": "e6f286c6-8d5f-4ce3-a365-4b6105e49ed9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/11-785 Project/MNIST_CSV.zip' MNIST_CSV.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "YDSWbKbx7QMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bfd7e2-10d8-4b46-de22-f2be6f3da481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  MNIST_CSV.zip\n",
            "  inflating: generate_mnist_csv.py   \n",
            "  inflating: mnist_test.csv          \n",
            "  inflating: mnist_train.csv         \n",
            "  inflating: readme.md               \n"
          ]
        }
      ],
      "source": [
        "!unzip MNIST_CSV.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "POb7_hvA4hFx"
      },
      "outputs": [],
      "source": [
        "n_epochs = 3\n",
        "batch_size_train = 32\n",
        "batch_size_test = 1000\n",
        "learning_rate = 0.01\n",
        "momentum = 0.5\n",
        "log_interval = 10\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)\n",
        "HYPER_GRAYSCALE = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "be_xMhZO5tfl"
      },
      "outputs": [],
      "source": [
        "train_set = pd.read_csv(\"mnist_train.csv\")\n",
        "test_images = pd.read_csv(\"mnist_test.csv\")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(train_set.iloc[:, 1:],\n",
        "                                                                     train_set.iloc[:, 0],\n",
        "                                                                     test_size=0.3)\n",
        "\n",
        "train_images.reset_index(drop=True, inplace=True)\n",
        "val_images.reset_index(drop=True, inplace=True)\n",
        "train_labels.reset_index(drop=True, inplace=True)\n",
        "val_labels.reset_index(drop=True, inplace=True)\n",
        "\n",
        "train_images = train_images.to_numpy(dtype='float32')\n",
        "train_labels = train_labels.to_numpy(dtype='float32')\n",
        "\n",
        "val_images = val_images.to_numpy(dtype='float32')\n",
        "val_labels = val_labels.to_numpy(dtype='float32')\n",
        "\n",
        "test_images = test_images.to_numpy(dtype='float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoi__a7H96Pm"
      },
      "source": [
        "## Jigsaw Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "gC4n7TMa7Yof"
      },
      "outputs": [],
      "source": [
        "class JigsawDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, permutations=10, img_transformer=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.permutations = permutations\n",
        "\n",
        "        self.N = len(self.images)\n",
        "        self.grid_size = 3\n",
        "\n",
        "    def __retrieve_permutations(self):\n",
        "        nums = range(self.grid_size * self.grid_size)\n",
        "\n",
        "        \"\"\"\n",
        "        permutations = []\n",
        "        for i in range(self.permutations):\n",
        "            permutations.append(np.random.permutation(nums))\n",
        "        \"\"\"\n",
        "\n",
        "        return np.random.permutation(nums)\n",
        "\n",
        "    def __get_image(self, index):\n",
        "        return self.images[index]\n",
        "\n",
        "    def __get_tiles(self, index):\n",
        "        img = self.__get_image(index).reshape(28, 28)\n",
        "        tiles = np.zeros((9, 9, 9), dtype='float32')\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                tiles[i * 3 + j] = img[i*9:i*9+9, j*9:j*9+9]\n",
        "\n",
        "        return tiles\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        n_grids = self.grid_size ** 2\n",
        "        tiles = self.__get_tiles(index)\n",
        "\n",
        "        order = self.__retrieve_permutations()\n",
        "\n",
        "        data_index = torch.from_numpy(np.array(order))\n",
        "\n",
        "        data = [torch.from_numpy(tiles[order[t]]) for t in range(n_grids)]\n",
        "\n",
        "        item = torch.stack(data, 0)\n",
        "        return item, order, int(self.labels[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "nscImNp2utw9"
      },
      "outputs": [],
      "source": [
        "class JigsawDataset_State(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, labels, permutations=10, img_transformer=None, img_grayscale = HYPER_GRAYSCALE):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.permutations = permutations\n",
        "\n",
        "        self.N = len(self.images)\n",
        "        self.grid_size = 3\n",
        "        self.GRAYSCALE = HYPER_GRAYSCALE\n",
        "\n",
        "    def __retrieve_permutations(self):\n",
        "        nums = range(self.grid_size * self.grid_size)\n",
        "\n",
        "        \"\"\"\n",
        "        permutations = []\n",
        "        for i in range(self.permutations):\n",
        "            permutations.append(np.random.permutation(nums))\n",
        "        \"\"\"\n",
        "\n",
        "        return np.random.permutation(nums)\n",
        "\n",
        "    def __get_image(self, index):\n",
        "        img = self.images[index].reshape(28, 28)\n",
        "        if self.GRAYSCALE:\n",
        "          img = np.repeat(img[ np.newaxis, :, :], 3, axis=0)\n",
        "        return img\n",
        "\n",
        "    def __get_state(self, index, current_pieces, piece_list, order, tile_list):\n",
        "        img = self.__get_image(index)\n",
        "        tiles = np.zeros((9, 3, 9, 9), dtype='float32')\n",
        "\n",
        "        for i in range(3):\n",
        "          for j in range(3):\n",
        "\n",
        "            a = i * 3 + j\n",
        "            tiles[a] = img[:,i*9:i*9+9, j*9:j*9+9]\n",
        "            if a not in piece_list:\n",
        "              img[:,i*9:i*9+9, j*9:j*9+9] = 0\n",
        "\n",
        "        return img, tiles\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        n_grids = self.grid_size ** 2\n",
        "\n",
        "        current_pieces = np.random.randint(0,9)\n",
        "        current_pieces = 8\n",
        "        order = self.__retrieve_permutations()\n",
        "\n",
        "        piece_list = np.random.choice(9, current_pieces, replace=False)\n",
        "        # piece_list = [piece_list_unshuffled[x] for x in order]\n",
        "        tile_list = [i for i in order if i not in piece_list]\n",
        "\n",
        "\n",
        "        img, tiles = self.__get_state(index, current_pieces, piece_list, order, tile_list)\n",
        "\n",
        "        data_index = torch.from_numpy(np.array(order))\n",
        "\n",
        "        tiles_shuffl = [torch.from_numpy(tiles[x]) for x in tile_list]\n",
        "\n",
        "\n",
        "        return img, current_pieces, tiles, tiles_shuffl[0], tile_list[0], order, int(self.labels[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIR4ZOdCgWZa"
      },
      "source": [
        "### Test Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FlSRW7vV_On7"
      },
      "outputs": [],
      "source": [
        "class JigsawDatasetTest(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, permutations=10, img_transformer=None):\n",
        "        self.images = images\n",
        "        self.permutations = permutations\n",
        "\n",
        "        self.N = len(self.images)\n",
        "        self.grid_size = 3\n",
        "\n",
        "    def __retrieve_permutations(self):\n",
        "        nums = range(self.grid_size * self.grid_size)\n",
        "\n",
        "        \"\"\"\n",
        "        permutations = []\n",
        "        for i in range(self.permutations):\n",
        "            permutations.append(np.random.permutation(nums))\n",
        "        \"\"\"\n",
        "\n",
        "        return np.random.permutation(nums)\n",
        "\n",
        "    def __get_image(self, index):\n",
        "        return self.images[index]\n",
        "\n",
        "    def __get_tiles(self, index):\n",
        "        img = self.__get_image(index).reshape(28, 28)\n",
        "        tiles = np.zeros((9, 9, 9), dtype='float32')\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                tiles[i * 3 + j] = img[i*9:i*9+9, j*9:j*9+9]\n",
        "\n",
        "        return tiles\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        n_grids = self.grid_size ** 2\n",
        "        tiles = self.__get_tiles(index)\n",
        "\n",
        "        order = self.__retrieve_permutations()\n",
        "\n",
        "        data_index = torch.from_numpy(np.array(order))\n",
        "\n",
        "        data = [torch.from_numpy(tiles[order[t]]) for t in range(n_grids)]\n",
        "\n",
        "        item = torch.stack(data, 0)\n",
        "        return item, order\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "pCbZylM9uqP8"
      },
      "outputs": [],
      "source": [
        "class JigsawDatasetTest_State(torch.utils.data.Dataset):\n",
        "    def __init__(self, images, permutations=10, img_transformer=None):\n",
        "        self.images = images\n",
        "        self.permutations = permutations\n",
        "\n",
        "        self.N = len(self.images)\n",
        "        self.grid_size = 3\n",
        "\n",
        "    def __retrieve_permutations(self):\n",
        "        nums = range(self.grid_size * self.grid_size)\n",
        "\n",
        "        \"\"\"\n",
        "        permutations = []\n",
        "        for i in range(self.permutations):\n",
        "            permutations.append(np.random.permutation(nums))\n",
        "        \"\"\"\n",
        "\n",
        "        return np.random.permutation(nums)\n",
        "\n",
        "    def __get_image(self, index):\n",
        "        return self.images[index]\n",
        "\n",
        "    def __get_tiles(self, index):\n",
        "        img = self.__get_image(index).reshape(28, 28)\n",
        "        tiles = np.zeros((9, 9, 9), dtype='float32')\n",
        "\n",
        "        for i in range(3):\n",
        "            for j in range(3):\n",
        "                tiles[i * 3 + j] = img[i*9:i*9+9, j*9:j*9+9]\n",
        "\n",
        "        return tiles\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        n_grids = self.grid_size ** 2\n",
        "        tiles = self.__get_tiles(index)\n",
        "\n",
        "        order = self.__retrieve_permutations()\n",
        "\n",
        "        data_index = torch.from_numpy(np.array(order))\n",
        "\n",
        "        data = [torch.from_numpy(tiles[order[t]]) for t in range(n_grids)]\n",
        "\n",
        "        item = torch.stack(data, 0)\n",
        "        return item, order\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-uiBAdgdm7"
      },
      "source": [
        "# Initialize the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZ_Zfxy7fK-",
        "outputId": "4da3a530-daee-4044-8eb2-e20b6c1cd5b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset samples = 41999, batches = 41999\n",
            "Val dataset samples = 18000, batches = 18000\n",
            "Test dataset samples = 9999, batches = 9999\n"
          ]
        }
      ],
      "source": [
        "train_data = JigsawDataset(train_images, train_labels)\n",
        "val_data = JigsawDataset(val_images, val_labels)\n",
        "test_data = JigsawDatasetTest(test_images)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        dataset     = train_data,\n",
        "        num_workers = 2,\n",
        "        batch_size  = 1,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = True,\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "        dataset     = val_data,\n",
        "        num_workers = 1,\n",
        "        batch_size  = 1,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = False,\n",
        "    )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        dataset     = test_data,\n",
        "        num_workers = 1,\n",
        "        batch_size  = 1,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = False,\n",
        "    )\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H6JLpkFB9GoO"
      },
      "outputs": [],
      "source": [
        "train_data_state = JigsawDataset_State(train_images, train_labels)\n",
        "val_data_state = JigsawDataset_State(val_images, val_labels)\n",
        "test_data_state = JigsawDatasetTest_State(test_images)\n",
        "\n",
        "train_loader_state = torch.utils.data.DataLoader(\n",
        "        dataset     = train_data_state,\n",
        "        num_workers = 2,\n",
        "        batch_size  = batch_size_train,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = True,\n",
        ")\n",
        "\n",
        "val_loader_state = torch.utils.data.DataLoader(\n",
        "        dataset     = val_data_state,\n",
        "        num_workers = 1,\n",
        "        batch_size  = batch_size_train,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = False,\n",
        "    )\n",
        "\n",
        "test_loader_state = torch.utils.data.DataLoader(\n",
        "        dataset     = test_data_state,\n",
        "        num_workers = 1,\n",
        "        batch_size  = batch_size_test,\n",
        "        pin_memory  = True,\n",
        "        shuffle     = False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Q6JFn5-ARo"
      },
      "source": [
        "### Test the Datasets and Plot some inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c9eq7V3D8XjL",
        "outputId": "df1f80b5-c985-4e82-ac19-b3d73bef0c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4, 7, 3, 2, 6, 0, 5, 8, 1]])\n",
            "tensor([0])\n",
            "tensor([5])\n",
            "tensor([8])\n",
            "tensor([3])\n",
            "tensor([2])\n",
            "tensor([0])\n",
            "tensor([6])\n",
            "tensor([4])\n",
            "tensor([1])\n",
            "tensor([7])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for tiles, order, label in train_loader:\n",
        "  fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(8,8))\n",
        "  fig.subplots_adjust(hspace=.2)\n",
        "\n",
        "  for i in range(3):\n",
        "      for j in range(3):\n",
        "          ax[i][j].axis('off')\n",
        "          ax[i][j].imshow(tiles[0][i * 3 + j], cmap='gray')\n",
        "  print(order)\n",
        "  print(label)\n",
        "\n",
        "  fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(8,8))\n",
        "  fig.subplots_adjust(hspace=.2)\n",
        "\n",
        "  for i in range(3):\n",
        "      for j in range(3):\n",
        "          ax[i][j].axis('off')\n",
        "          print((order[0]==i * 3 + j).nonzero(as_tuple=True)[0])\n",
        "          ax[i][j].imshow(tiles[0][(order[0]==i * 3 + j).nonzero(as_tuple=True)[0].item()], cmap='gray')\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "Of2vuSQx9hN_",
        "outputId": "3e823a48-8255-4b27-a371-2795c0bdab1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 3, 28, 28])\n",
            "torch.Size([32, 3, 9, 9])\n",
            "tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
            "        8, 8, 8, 8, 8, 8, 8, 8])\n",
            "tensor([3, 0, 7, 2, 4, 8, 7, 5, 3, 3, 6, 6, 0, 6, 2, 1, 1, 1, 7, 0, 2, 6, 5, 5,\n",
            "        4, 6, 7, 3, 8, 6, 2, 8])\n",
            "tensor([6, 0, 1, 2, 3, 4, 8, 7, 5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "for img, cur_pieces, tiles, tiles_shuffl, tile_list, order, label in train_loader_state:\n",
        "  fig, ax = plt.subplots( ncols=2, figsize=(15,15))\n",
        "  fig.subplots_adjust(hspace=.2)\n",
        "\n",
        "  print(img.shape)\n",
        "  print(tiles_shuffl.shape)\n",
        "  # print(cur_pieces[0])\n",
        "  ax[0].axis('off')\n",
        "  ax[0].imshow(img[0,0,:,:], cmap='gray')\n",
        "  print(cur_pieces)\n",
        "  print(tile_list)\n",
        "  print(order[0])\n",
        "  ax[1].imshow(tiles_shuffl[0,0,:,:], cmap='gray')\n",
        "\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxQyWD50iZ6o"
      },
      "source": [
        "## Monte Carlo Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xmDvJbHvCjGb"
      },
      "outputs": [],
      "source": [
        "class MonteCarloTreeSearchNode():\n",
        "    def __init__(self, state, parent=None, parent_action=None):\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.parent_action = parent_action\n",
        "        self.children = []\n",
        "        self._number_of_visits = 0\n",
        "        self._results =  []\n",
        "        # self._results[1] = 0\n",
        "        # self._results[-1] = 0\n",
        "        self._untried_actions = None\n",
        "        self._untried_actions = self.untried_actions()\n",
        "        return\n",
        "\n",
        "    def untried_actions(self):\n",
        "\n",
        "        self._untried_actions = self.state.get_legal_actions()\n",
        "        return self._untried_actions\n",
        "    # Returns the list of untried actions from a given state. For the first turn of our game there are 81 possible actions. For the second turn it is 8 or 9. This varies in our game.\n",
        "\n",
        "    def q(self):\n",
        "        score = np.sum(self._results)\n",
        "        return score\n",
        "    # Returns the difference of wins - losses\n",
        "\n",
        "    def n(self):\n",
        "        return self._number_of_visits\n",
        "    # Returns the number of times each node is visited.\n",
        "\n",
        "    def expand(self):\n",
        "\n",
        "        action = self._untried_actions.pop() #Maybe add ran\n",
        "        next_state = self.state.move(action)\n",
        "        child_node = MonteCarloTreeSearchNode(\n",
        "        next_state, parent=self, parent_action=action)\n",
        "\n",
        "        self.children.append(child_node)\n",
        "        return child_node\n",
        "    # From the present state, next state is generated depending on the action which is carried out. In this step all the possible child nodes corresponding to generated states are appended to the children array and the child_node is returned. The states which are possible from the present state are all generated and the child_node corresponding to this generated state is returned.\n",
        "\n",
        "    def is_terminal_node(self):\n",
        "        return self.state.is_game_over()\n",
        "    # This is used to check if the current node is terminal or not. Terminal node is reached when the game is over.\n",
        "\n",
        "    def rollout(self):\n",
        "        current_rollout_state = self.state\n",
        "\n",
        "        while not current_rollout_state.is_game_over():\n",
        "\n",
        "            possible_moves = current_rollout_state.get_legal_actions()\n",
        "\n",
        "            action = self.rollout_policy(possible_moves)\n",
        "            current_rollout_state = current_rollout_state.move(action)\n",
        "        # print('in rollout', current_rollout_state.tiles_selected)\n",
        "        return current_rollout_state.game_result()\n",
        "    # From the current state, entire game is simulated till there is an outcome for the game. This outcome of the game is returned. For example if it results in a win, the outcome is 1. Otherwise it is -1 if it results in a loss. And it is 0 if it is a tie. If the entire game is randomly simulated, that is at each turn the move is randomly selected out of set of possible moves, it is called light playout.\n",
        "\n",
        "    def backpropagate(self, result):\n",
        "        self._number_of_visits += 1.\n",
        "        self._results += [result]\n",
        "        # print('Backpropagate', self.state.tiles_selected, self._results)\n",
        "        if self.parent:\n",
        "            self.parent.backpropagate(result)\n",
        "    # In this step all the statistics for the nodes are updated. Untill the parent node is reached, the number of visits for each node is incremented by 1. If the result is 1, that is it resulted in a win, then the win is incremented by 1. Otherwise if result is a loss, then loss is incremented by 1.\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self._untried_actions) == 0\n",
        "\n",
        "    # All the actions are poped out of _untried_actions one by one. When it becomes empty, that is when the size is zero, it is fully expanded.\n",
        "\n",
        "    def best_child(self, c_param=0.1):\n",
        "\n",
        "        # print('best_child',[x.state.tiles_selected for x in self.children])\n",
        "        choices_weights = [(c.q() / c.n()) + c_param * np.sqrt((2 * np.log(self.n()) / c.n())) for c in self.children]\n",
        "        # print('choices_weights', choices_weights)\n",
        "        return self.children[np.argmax(choices_weights)]\n",
        "\n",
        "    # Once fully expanded, this function selects the best child out of the children array. The first term in the formula corresponds to exploitation and the second term corresponds to exploration.\n",
        "\n",
        "    def rollout_policy(self, possible_moves):\n",
        "\n",
        "        return possible_moves[np.random.randint(len(possible_moves))]\n",
        "\n",
        "    # Randomly selects a move out of possible moves. This is an example of random playout.\n",
        "\n",
        "    def _tree_policy(self):\n",
        "\n",
        "        current_node = self\n",
        "        while not current_node.is_terminal_node():\n",
        "\n",
        "            if not current_node.is_fully_expanded():\n",
        "                return current_node.expand()\n",
        "            else:\n",
        "                # print('going into best child')\n",
        "                # print('current_node', current_node.state.tiles_selected)\n",
        "                current_node = current_node.best_child()\n",
        "                # print('best_child', current_node.state.tiles_selected)\n",
        "                # print('is_terminal', current_node.is_terminal_node())\n",
        "        return current_node\n",
        "    # Selects node to run rollout.\n",
        "\n",
        "    def best_action(self):\n",
        "        simulation_no = 100\n",
        "\n",
        "\n",
        "        for i in range(simulation_no):\n",
        "            # print('sim',i)\n",
        "            v = self._tree_policy()\n",
        "            # print('Tree policy',v.state.tiles_selected)\n",
        "            reward = v.rollout()\n",
        "            v.backpropagate(reward)\n",
        "            # print('reward',v.state.tiles_selected, reward)\n",
        "\n",
        "        return self.best_child(c_param=0.)\n",
        "    # This is the best action function which returns the node corresponding to best possible move. The step of expansion, simulation and backpropagation are carried out by the code above.\n",
        "\n",
        "class State:\n",
        "    def __init__(self, tiles_selected=[], final_shuffle_list=None):\n",
        "        self.tiles_selected = tiles_selected\n",
        "        self.final_shuffle_list = final_shuffle_list\n",
        "\n",
        "    def get_legal_actions(self):\n",
        "        '''\n",
        "        Modify according to your game or\n",
        "        needs. Constructs a list of all\n",
        "        possible actions from current state.\n",
        "        Returns a list.\n",
        "        '''\n",
        "        total_tiles = list(range(0,9))\n",
        "        legal_actions = [i for i in total_tiles if i not in self.tiles_selected]\n",
        "        return legal_actions\n",
        "\n",
        "    def is_game_over(self):\n",
        "        '''\n",
        "        Modify according to your game or\n",
        "        needs. It is the game over condition\n",
        "        and depends on your game. Returns\n",
        "        true or false\n",
        "        '''\n",
        "        return len(self.tiles_selected) == 9\n",
        "\n",
        "    def game_result(self):\n",
        "        '''\n",
        "        Modify according to your game or\n",
        "        needs. Returns 1 or 0 or -1 depending\n",
        "        on your state corresponding to win,\n",
        "        tie or a loss.\n",
        "        '''\n",
        "        #Current tiles permutation is the same as required tiles permutation\n",
        "        matches = 0\n",
        "        for i in range(len(self.tiles_selected)):\n",
        "          if self.tiles_selected[i] == self.final_shuffle_list[i]:\n",
        "            matches +=1\n",
        "        return matches\n",
        "    def move(self,action):\n",
        "        '''\n",
        "        #Action will be a tile number\n",
        "        Modify according to your game or\n",
        "        needs. Changes the state of your\n",
        "        board with a new value. For a normal\n",
        "        Tic Tac Toe game, it can be a 3 by 3\n",
        "        array with all the elements of array\n",
        "        being 0 initially. 0 means the board\n",
        "        position is empty. If you place x in\n",
        "        row 2 column 3, then it would be some\n",
        "        thing like board[2][3] = 1, where 1\n",
        "        represents that x is placed. Returns\n",
        "        the new state after making a move.\n",
        "        '''\n",
        "        new_tiles_selected = [x for x in self.tiles_selected]\n",
        "        new_tiles_selected.append(action)\n",
        "        return State(tiles_selected=new_tiles_selected, final_shuffle_list=self.final_shuffle_list)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr6MqMqPC-v7",
        "outputId": "f871ec7f-307d-41a6-82e9-2d92be233516"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8, 7, 0, 6, 1, 5, 2, 4, 3]\n",
            "[2, 4, 6, 8, 7, 5, 3, 1, 0]\n",
            "[]\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Monte Carlo\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "FINAL BEST ACTION [8]\n",
            "FINAL BEST ACTION [8, 7]\n",
            "FINAL BEST ACTION [8, 7, 0]\n",
            "FINAL BEST ACTION [8, 7, 0, 6]\n",
            "FINAL BEST ACTION [8, 7, 0, 6, 1]\n",
            "FINAL BEST ACTION [8, 7, 0, 6, 1, 5]\n",
            "FINAL BEST ACTION [8, 7, 0, 6, 1, 5, 2]\n",
            "FINAL BEST ACTION [8, 7, 0, 6, 1, 5, 2, 4]\n",
            "FINAL BEST ACTION [8, 7, 0, 6, 1, 5, 2, 4, 3]\n"
          ]
        }
      ],
      "source": [
        "shuffle = [2, 4, 6, 8, 7, 5, 3, 1, 0]\n",
        "final_shuffle_list = [-1]*9\n",
        "for i in range(9):\n",
        "  final_shuffle_list[shuffle[i]]= i\n",
        "print(final_shuffle_list)\n",
        "print(shuffle)\n",
        "initial_state = State(final_shuffle_list = final_shuffle_list)\n",
        "print(initial_state.tiles_selected)\n",
        "print(initial_state.get_legal_actions())\n",
        "print('Monte Carlo')\n",
        "root = MonteCarloTreeSearchNode(state = initial_state)\n",
        "print(root._untried_actions)\n",
        "while len(root._untried_actions) != 0:\n",
        "  selected_node = root.best_action()\n",
        "  print('FINAL BEST ACTION', selected_node.state.tiles_selected)\n",
        "  root = MonteCarloTreeSearchNode(state = selected_node.state)\n",
        "\n",
        "# print(root._untried_actions)\n",
        "# selected_node = root.best_action()\n",
        "# print(root._untried_actions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWfr3QK7hlVB"
      },
      "source": [
        "## Feature Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "g3oYMiqyvwij"
      },
      "outputs": [],
      "source": [
        "class FeatureNetwork1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 28, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        self.drop1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(28, 1, kernel_size=(3,3), stride=1, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "        # self.fc3 = nn.Linear(128, 16)\n",
        "        # self.act3 = nn.ReLU()\n",
        "        # # self.drop3 = nn.Dropout(0.1)\n",
        "\n",
        "        # self.fc4 = nn.Linear(16, 1)\n",
        "        # self.act4 = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input 3x32x32, output 32x32x32\n",
        "        x = self.act1(self.conv1(x))\n",
        "        # x = self.drop1(x)\n",
        "        # input 32x32x32, output 32x32x32\n",
        "        x = self.act2(self.conv2(x))\n",
        "        # input 32x32x32, output 32x16x16\n",
        "        x = self.pool2(x)\n",
        "        # input 32x16x16, output 8192\n",
        "        x = self.flat(x)\n",
        "        # # input 8192, output 512\n",
        "        # x = self.act3(self.fc3(x))\n",
        "        # # x = self.drop3(x)\n",
        "        # # input 512, output 10\n",
        "        # x = self.fc4(x)\n",
        "        # x = self.act4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "O-EkrZbFwzzt"
      },
      "outputs": [],
      "source": [
        "class FeatureNetwork2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 9, kernel_size=(2,2), stride=1, padding=1)\n",
        "        self.act1 = nn.ReLU()\n",
        "        # self.drop1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(9, 1, kernel_size=(2,2), stride=1, padding=1)\n",
        "        self.act2 = nn.ReLU()\n",
        "        # self.pool2 = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print('FeatureNetwork2')\n",
        "        # input 3x32x32, output 32x32x32\n",
        "        # print('imput',x)\n",
        "        x = self.act1(self.conv1(x))\n",
        "        # print(x)\n",
        "        # x = self.drop1(x)\n",
        "        # input 32x32x32, output 32x32x32\n",
        "        x = self.act2(self.conv2(x))\n",
        "        # input 32x32x32, output 32x16x16\n",
        "        # x = self.pool2(x)\n",
        "\n",
        "        # input 32x16x16, output 8192\n",
        "        x = self.flat(x)\n",
        "\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J0B4BPwjdaGd"
      },
      "outputs": [],
      "source": [
        "class CombinationLayer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.comb = nn.Bilinear(196, 121, 9)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # input 3x32x32, output 32x32x32\n",
        "        z = self.comb(x,y)\n",
        "        # z = self.softmax(z)\n",
        "\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZVYIr8o5-6E1"
      },
      "outputs": [],
      "source": [
        "class JigsawModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.FeatureNetwork1  = FeatureNetwork1()\n",
        "        self.FeatureNetwork2  = FeatureNetwork2()\n",
        "        self.CombinationLayer  = CombinationLayer()\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        x1 = self.FeatureNetwork1(x)\n",
        "        y1 = self.FeatureNetwork2(y)\n",
        "        z = self.CombinationLayer(x1, y1)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRfCSNWjnXxT",
        "outputId": "70281d19-9ae5-4472-9c4f-18c81fdcba9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 28, 28, 28]             784\n",
            "              ReLU-2           [-1, 28, 28, 28]               0\n",
            "            Conv2d-3            [-1, 1, 28, 28]             253\n",
            "              ReLU-4            [-1, 1, 28, 28]               0\n",
            "         MaxPool2d-5            [-1, 1, 14, 14]               0\n",
            "           Flatten-6                  [-1, 196]               0\n",
            "   FeatureNetwork1-7                  [-1, 196]               0\n",
            "            Conv2d-8            [-1, 9, 10, 10]             117\n",
            "              ReLU-9            [-1, 9, 10, 10]               0\n",
            "           Conv2d-10            [-1, 1, 11, 11]              37\n",
            "             ReLU-11            [-1, 1, 11, 11]               0\n",
            "          Flatten-12                  [-1, 121]               0\n",
            "  FeatureNetwork2-13                  [-1, 121]               0\n",
            "         Bilinear-14                    [-1, 9]         213,453\n",
            " CombinationLayer-15                    [-1, 9]               0\n",
            "================================================================\n",
            "Total params: 214,644\n",
            "Trainable params: 214,644\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.18\n",
            "Forward/backward pass size (MB): 0.37\n",
            "Params size (MB): 0.82\n",
            "Estimated Total Size (MB): 3.37\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "test_FeatureNetwork1 = JigsawModel().to(DEVICE)\n",
        "summary(test_FeatureNetwork1, [(3, 28, 28),(3, 9, 9)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELWRrI7MhpnJ"
      },
      "source": [
        "## Feature Network with Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZSoOnBrDhtyN"
      },
      "outputs": [],
      "source": [
        "class FeatureNetwork1_RN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        self.linear = nn.Linear(1000, 256)\n",
        "        self.act = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(256, 256)\n",
        "        # self.linear2 = nn.Linear(16, 1)\n",
        "        # self.softmax = nn.Softmax()\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.resnet(x)\n",
        "        x = self.linear(x)\n",
        "        x = self.act(x)\n",
        "        x = self.linear2(x)\n",
        "        # x = self.softmax(x)\n",
        "        x = self.flat(x)\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IxiTpZ-DhxDI"
      },
      "outputs": [],
      "source": [
        "class FeatureNetwork2_RN(nn.Module):\n",
        "    def __init__(self):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.resnet = torchvision.models.resnet18(pretrained=True)\n",
        "        self.linear = nn.Linear(1000, 128)\n",
        "        self.act = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(128, 64)\n",
        "        # self.linear2 = nn.Linear(16, 1)\n",
        "        # self.softmax = nn.Softmax()\n",
        "        self.flat = nn.Flatten()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.resnet(x)\n",
        "        x = self.linear(x)\n",
        "        x = self.act(x)\n",
        "        x = self.linear2(x)\n",
        "        # x = self.softmax(x)\n",
        "        x = self.flat(x)\n",
        "        x = torch.squeeze(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XbQ7k8YCh1Ae"
      },
      "outputs": [],
      "source": [
        "class CombinationLayer_RN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.comb = nn.Bilinear(256, 64, 9)\n",
        "        self.softmax = nn.Softmax()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        # input 3x32x32, output 32x32x32\n",
        "        z = self.comb(x,y)\n",
        "        # z = self.softmax(z)\n",
        "\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dhU_zLL_RA2-"
      },
      "outputs": [],
      "source": [
        "class JigsawModel_RN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.FeatureNetwork1  = FeatureNetwork1_RN()\n",
        "        self.FeatureNetwork2  = FeatureNetwork2_RN()\n",
        "        self.CombinationLayer  = CombinationLayer_RN()\n",
        "\n",
        "        self.linear = nn.Linear(320, 128)\n",
        "        self.act = nn.ReLU()\n",
        "        self.linear2 = nn.Linear(128, 9)\n",
        "\n",
        "\n",
        "    def forward(self, x, y):\n",
        "\n",
        "        x1 = self.FeatureNetwork1(x)\n",
        "        y1 = self.FeatureNetwork2(y)\n",
        "        z =  torch.cat((x1, y1), dim = -1)\n",
        "        # z = self.CombinationLayer(x1, y1)\n",
        "        z = self.linear(z)\n",
        "        z = self.act(z)\n",
        "        z = self.linear2(z)\n",
        "        return z"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "IPxqwYtyX6BQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ee5ae8-5113-417f-c051-cdcf6aba41da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 59.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 14, 14]           9,408\n",
            "       BatchNorm2d-2           [-1, 64, 14, 14]             128\n",
            "              ReLU-3           [-1, 64, 14, 14]               0\n",
            "         MaxPool2d-4             [-1, 64, 7, 7]               0\n",
            "            Conv2d-5             [-1, 64, 7, 7]          36,864\n",
            "       BatchNorm2d-6             [-1, 64, 7, 7]             128\n",
            "              ReLU-7             [-1, 64, 7, 7]               0\n",
            "            Conv2d-8             [-1, 64, 7, 7]          36,864\n",
            "       BatchNorm2d-9             [-1, 64, 7, 7]             128\n",
            "             ReLU-10             [-1, 64, 7, 7]               0\n",
            "       BasicBlock-11             [-1, 64, 7, 7]               0\n",
            "           Conv2d-12             [-1, 64, 7, 7]          36,864\n",
            "      BatchNorm2d-13             [-1, 64, 7, 7]             128\n",
            "             ReLU-14             [-1, 64, 7, 7]               0\n",
            "           Conv2d-15             [-1, 64, 7, 7]          36,864\n",
            "      BatchNorm2d-16             [-1, 64, 7, 7]             128\n",
            "             ReLU-17             [-1, 64, 7, 7]               0\n",
            "       BasicBlock-18             [-1, 64, 7, 7]               0\n",
            "           Conv2d-19            [-1, 128, 4, 4]          73,728\n",
            "      BatchNorm2d-20            [-1, 128, 4, 4]             256\n",
            "             ReLU-21            [-1, 128, 4, 4]               0\n",
            "           Conv2d-22            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-23            [-1, 128, 4, 4]             256\n",
            "           Conv2d-24            [-1, 128, 4, 4]           8,192\n",
            "      BatchNorm2d-25            [-1, 128, 4, 4]             256\n",
            "             ReLU-26            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-27            [-1, 128, 4, 4]               0\n",
            "           Conv2d-28            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-29            [-1, 128, 4, 4]             256\n",
            "             ReLU-30            [-1, 128, 4, 4]               0\n",
            "           Conv2d-31            [-1, 128, 4, 4]         147,456\n",
            "      BatchNorm2d-32            [-1, 128, 4, 4]             256\n",
            "             ReLU-33            [-1, 128, 4, 4]               0\n",
            "       BasicBlock-34            [-1, 128, 4, 4]               0\n",
            "           Conv2d-35            [-1, 256, 2, 2]         294,912\n",
            "      BatchNorm2d-36            [-1, 256, 2, 2]             512\n",
            "             ReLU-37            [-1, 256, 2, 2]               0\n",
            "           Conv2d-38            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-39            [-1, 256, 2, 2]             512\n",
            "           Conv2d-40            [-1, 256, 2, 2]          32,768\n",
            "      BatchNorm2d-41            [-1, 256, 2, 2]             512\n",
            "             ReLU-42            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-43            [-1, 256, 2, 2]               0\n",
            "           Conv2d-44            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-45            [-1, 256, 2, 2]             512\n",
            "             ReLU-46            [-1, 256, 2, 2]               0\n",
            "           Conv2d-47            [-1, 256, 2, 2]         589,824\n",
            "      BatchNorm2d-48            [-1, 256, 2, 2]             512\n",
            "             ReLU-49            [-1, 256, 2, 2]               0\n",
            "       BasicBlock-50            [-1, 256, 2, 2]               0\n",
            "           Conv2d-51            [-1, 512, 1, 1]       1,179,648\n",
            "      BatchNorm2d-52            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-53            [-1, 512, 1, 1]               0\n",
            "           Conv2d-54            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-55            [-1, 512, 1, 1]           1,024\n",
            "           Conv2d-56            [-1, 512, 1, 1]         131,072\n",
            "      BatchNorm2d-57            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-58            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-59            [-1, 512, 1, 1]               0\n",
            "           Conv2d-60            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-61            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-62            [-1, 512, 1, 1]               0\n",
            "           Conv2d-63            [-1, 512, 1, 1]       2,359,296\n",
            "      BatchNorm2d-64            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-65            [-1, 512, 1, 1]               0\n",
            "       BasicBlock-66            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
            "           Linear-68                 [-1, 1000]         513,000\n",
            "           ResNet-69                 [-1, 1000]               0\n",
            "           Linear-70                  [-1, 256]         256,256\n",
            "             ReLU-71                  [-1, 256]               0\n",
            "           Linear-72                  [-1, 256]          65,792\n",
            "          Flatten-73                  [-1, 256]               0\n",
            "FeatureNetwork1_RN-74                  [-1, 256]               0\n",
            "           Conv2d-75             [-1, 64, 5, 5]           9,408\n",
            "      BatchNorm2d-76             [-1, 64, 5, 5]             128\n",
            "             ReLU-77             [-1, 64, 5, 5]               0\n",
            "        MaxPool2d-78             [-1, 64, 3, 3]               0\n",
            "           Conv2d-79             [-1, 64, 3, 3]          36,864\n",
            "      BatchNorm2d-80             [-1, 64, 3, 3]             128\n",
            "             ReLU-81             [-1, 64, 3, 3]               0\n",
            "           Conv2d-82             [-1, 64, 3, 3]          36,864\n",
            "      BatchNorm2d-83             [-1, 64, 3, 3]             128\n",
            "             ReLU-84             [-1, 64, 3, 3]               0\n",
            "       BasicBlock-85             [-1, 64, 3, 3]               0\n",
            "           Conv2d-86             [-1, 64, 3, 3]          36,864\n",
            "      BatchNorm2d-87             [-1, 64, 3, 3]             128\n",
            "             ReLU-88             [-1, 64, 3, 3]               0\n",
            "           Conv2d-89             [-1, 64, 3, 3]          36,864\n",
            "      BatchNorm2d-90             [-1, 64, 3, 3]             128\n",
            "             ReLU-91             [-1, 64, 3, 3]               0\n",
            "       BasicBlock-92             [-1, 64, 3, 3]               0\n",
            "           Conv2d-93            [-1, 128, 2, 2]          73,728\n",
            "      BatchNorm2d-94            [-1, 128, 2, 2]             256\n",
            "             ReLU-95            [-1, 128, 2, 2]               0\n",
            "           Conv2d-96            [-1, 128, 2, 2]         147,456\n",
            "      BatchNorm2d-97            [-1, 128, 2, 2]             256\n",
            "           Conv2d-98            [-1, 128, 2, 2]           8,192\n",
            "      BatchNorm2d-99            [-1, 128, 2, 2]             256\n",
            "            ReLU-100            [-1, 128, 2, 2]               0\n",
            "      BasicBlock-101            [-1, 128, 2, 2]               0\n",
            "          Conv2d-102            [-1, 128, 2, 2]         147,456\n",
            "     BatchNorm2d-103            [-1, 128, 2, 2]             256\n",
            "            ReLU-104            [-1, 128, 2, 2]               0\n",
            "          Conv2d-105            [-1, 128, 2, 2]         147,456\n",
            "     BatchNorm2d-106            [-1, 128, 2, 2]             256\n",
            "            ReLU-107            [-1, 128, 2, 2]               0\n",
            "      BasicBlock-108            [-1, 128, 2, 2]               0\n",
            "          Conv2d-109            [-1, 256, 1, 1]         294,912\n",
            "     BatchNorm2d-110            [-1, 256, 1, 1]             512\n",
            "            ReLU-111            [-1, 256, 1, 1]               0\n",
            "          Conv2d-112            [-1, 256, 1, 1]         589,824\n",
            "     BatchNorm2d-113            [-1, 256, 1, 1]             512\n",
            "          Conv2d-114            [-1, 256, 1, 1]          32,768\n",
            "     BatchNorm2d-115            [-1, 256, 1, 1]             512\n",
            "            ReLU-116            [-1, 256, 1, 1]               0\n",
            "      BasicBlock-117            [-1, 256, 1, 1]               0\n",
            "          Conv2d-118            [-1, 256, 1, 1]         589,824\n",
            "     BatchNorm2d-119            [-1, 256, 1, 1]             512\n",
            "            ReLU-120            [-1, 256, 1, 1]               0\n",
            "          Conv2d-121            [-1, 256, 1, 1]         589,824\n",
            "     BatchNorm2d-122            [-1, 256, 1, 1]             512\n",
            "            ReLU-123            [-1, 256, 1, 1]               0\n",
            "      BasicBlock-124            [-1, 256, 1, 1]               0\n",
            "          Conv2d-125            [-1, 512, 1, 1]       1,179,648\n",
            "     BatchNorm2d-126            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-127            [-1, 512, 1, 1]               0\n",
            "          Conv2d-128            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-129            [-1, 512, 1, 1]           1,024\n",
            "          Conv2d-130            [-1, 512, 1, 1]         131,072\n",
            "     BatchNorm2d-131            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-132            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-133            [-1, 512, 1, 1]               0\n",
            "          Conv2d-134            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-135            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-136            [-1, 512, 1, 1]               0\n",
            "          Conv2d-137            [-1, 512, 1, 1]       2,359,296\n",
            "     BatchNorm2d-138            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-139            [-1, 512, 1, 1]               0\n",
            "      BasicBlock-140            [-1, 512, 1, 1]               0\n",
            "AdaptiveAvgPool2d-141            [-1, 512, 1, 1]               0\n",
            "          Linear-142                 [-1, 1000]         513,000\n",
            "          ResNet-143                 [-1, 1000]               0\n",
            "          Linear-144                  [-1, 128]         128,128\n",
            "            ReLU-145                  [-1, 128]               0\n",
            "          Linear-146                   [-1, 64]           8,256\n",
            "         Flatten-147                   [-1, 64]               0\n",
            "FeatureNetwork2_RN-148                   [-1, 64]               0\n",
            "          Linear-149                  [-1, 128]          41,088\n",
            "            ReLU-150                  [-1, 128]               0\n",
            "          Linear-151                    [-1, 9]           1,161\n",
            "================================================================\n",
            "Total params: 23,879,705\n",
            "Trainable params: 23,879,705\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 2.18\n",
            "Forward/backward pass size (MB): 1.40\n",
            "Params size (MB): 91.09\n",
            "Estimated Total Size (MB): 94.67\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "test_FeatureNetwork1 = FeatureNetwork1_RN().to(DEVICE)\n",
        "# summary(test_FeatureNetwork1, (3, 28, 28))\n",
        "test_FeatureNetwork2 = JigsawModel_RN().to(DEVICE)\n",
        "summary(test_FeatureNetwork2, [(3, 28, 28),(3, 9, 9)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "164y5CEXjEAi"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "GO08ROtaQj8c"
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # Progress Bar\n",
        "    batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n",
        "\n",
        "    num_correct = 0\n",
        "    total_loss  = 0\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "\n",
        "        # optimizer.zero_grad() # Zero gradients\n",
        "\n",
        "        #9 datapoints\n",
        "\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it!\n",
        "            outputs = model(images)\n",
        "            loss    = criterion(outputs, labels)\n",
        "\n",
        "        # Update no. of correct predictions & loss as we iterate\n",
        "        num_correct     += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "        total_loss      += float(loss.item())\n",
        "\n",
        "        # tqdm lets you add some details so you can monitor training as you train.\n",
        "        batch_bar.set_postfix(\n",
        "            acc         = \"{:.04f}%\".format(100 * num_correct / (batch_size_train*(i + 1))),\n",
        "            loss        = \"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct = num_correct\n",
        "            # lr          = \"{:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "        )\n",
        "\n",
        "        # scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        # scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        # scaler.update()\n",
        "        loss.backward()\n",
        "\n",
        "        # TODO? Depending on your choice of scheduler,\n",
        "        # You may want to call some schdulers inside the train function. What are these?\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    acc         = 100 * num_correct / (batch_size_train* len(dataloader))\n",
        "    total_loss  = float(total_loss / len(dataloader))\n",
        "\n",
        "    return acc, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EMRNvJHk_LkZ"
      },
      "outputs": [],
      "source": [
        "def validate(model, dataloader, criterion):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(dataloader), dynamic_ncols=True, position=0, leave=False, desc='Val', ncols=5)\n",
        "\n",
        "    num_correct = 0.0\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for i, (images, labels) in enumerate(dataloader):\n",
        "\n",
        "        # Move images to device\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "        # Get model outputs\n",
        "        with torch.inference_mode():\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        num_correct += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "        total_loss += float(loss.item())\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            acc=\"{:.04f}%\".format(100 * num_correct / (config['batch_size']*(i + 1))),\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct=num_correct)\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "    acc = 100 * num_correct / (config['batch_size']* len(dataloader))\n",
        "    total_loss = float(total_loss / len(dataloader))\n",
        "    return acc, total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "agCh1WpPixn-"
      },
      "outputs": [],
      "source": [
        "#(empty, all fragments) -> we get probabilities, we compare it with yHot to get the criterion, and then backpropagate the loss to network\n",
        "#select the one with max probability (or) select any (fragment, true_position) pair at random\n",
        "#Recompute the datapoint, and then repeat the process - get probabilities network(data), criterio will be (true_positions, output_network) and loss.backward\n",
        "\n",
        "\n",
        "#Dataloader has true images, the digit - label;\n",
        "# Shuffled image, true position for each tile.\n",
        "\n",
        "\n",
        "#We need empty -> true image pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Lj_JvIvep-X-"
      },
      "outputs": [],
      "source": [
        "def replace(image, tile_position, new_tile , tile_height=9, tile_width=9):\n",
        "  st_row = (tile_position // 3 )*tile_height\n",
        "  en_row = st_row + tile_height\n",
        "  st_col = (tile_position % 3 )*tile_width\n",
        "  en_col = st_col + tile_width\n",
        "  image[0,st_row.to(torch.int64):en_row.to(torch.int64), st_col.to(torch.int64):en_col.to(torch.int64)] = new_tile\n",
        "\n",
        "  return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "eJyeeUOwkEdY"
      },
      "outputs": [],
      "source": [
        "def train2(model, shuffled_dataloader, criterion):\n",
        "  model.train()\n",
        "  total_loss = 0 #Wait\n",
        "\n",
        "  batch_bar   = tqdm(total=len(shuffled_dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n",
        "\n",
        "  j = 0\n",
        "  for (shuffled_tiles1, true_positions1, label) in shuffled_dataloader:\n",
        "    #to device\n",
        "\n",
        "    shuffled_tiles = shuffled_tiles1.clone().to(DEVICE)\n",
        "    true_positions = true_positions1.clone().to(DEVICE)\n",
        "\n",
        "    shuffled_tiles = shuffled_tiles1.reshape(9, 9, 9)\n",
        "    partial_image = torch.zeros((1,28,28))\n",
        "    selected_tiles = 0\n",
        "    selected_tiles_set = set()\n",
        "    # print('New image')\n",
        "    while selected_tiles < 9:\n",
        "      loss = 0\n",
        "      for i in range(len(shuffled_tiles)): #9\n",
        "        if i in selected_tiles_set: continue\n",
        "        tile = shuffled_tiles[i].reshape((1,9,9))\n",
        "        move_probs = model(partial_image, tile)\n",
        "        true_prob = torch.nn.functional.one_hot(true_positions[0][i].to(torch.int64), num_classes=9) #Tochange\n",
        "        loss1 = criterion(move_probs, true_prob.to(torch.float)[None, :])\n",
        "        loss += loss1\n",
        "        total_loss   += float(loss1.item())\n",
        "        # print('Outputs')\n",
        "        # # print(partial_image)\n",
        "        # print(tile)\n",
        "        # print(move_probs, selected_tiles_set )\n",
        "        # print(true_prob)\n",
        "      loss.backward(retain_graph=True)\n",
        "      optimizer.step()\n",
        "\n",
        "      selected_tile_index = np.random.randint(low= 0, high=9, size=(1,))[0] #make sure we don't select it again\n",
        "      while selected_tile_index in selected_tiles_set:\n",
        "        selected_tile_index = np.random.randint(low= 0, high=9, size=(1,))[0] #make sure we don't select it again\n",
        "\n",
        "      selected_tiles_set.add(selected_tile_index)\n",
        "      selected_tile_position = true_positions[0][selected_tile_index]\n",
        "\n",
        "      selected_tiles += 1\n",
        "      partial_image = replace(partial_image, selected_tile_position, shuffled_tiles[selected_tile_index], tile_height=9, tile_width=9)\n",
        "      plt.imshow(partial_image[0], cmap='gray')\n",
        "      # plt.plot()\n",
        "\n",
        "    # print(loss)\n",
        "    batch_bar.set_postfix(\n",
        "          loss        = \"{:.04f}\".format(float(total_loss / (j + 1))),\n",
        "          # lr          = \"{:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "      )\n",
        "    j += 1\n",
        "      # shuffled_tiles.remove(selected_tile_index)\n",
        "      # shuffled_tiles = torch.cat([shuffled_tiles[0:selected_tile_index], shuffled_tiles[selected_tile_index+1:]])\n",
        "      # true_positions = torch.cat([true_positions[0:selected_tile_index], true_positions[selected_tile_index+1:]])\n",
        "      # true_positions.remove(selected_tile_index)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kBerYA8lImE3"
      },
      "outputs": [],
      "source": [
        "def train_state(model, dataloader, criterion):\n",
        "\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  # Progress Bar\n",
        "  batch_bar   = tqdm(total=len(dataloader), dynamic_ncols=True, leave=False, position=0, desc='Train', ncols=5)\n",
        "\n",
        "  num_correct = 0\n",
        "  total_loss  = 0\n",
        "\n",
        "  for i, (img, cur_pieces, tiles, tiles_shuffl, tile_list, order, label) in enumerate(dataloader):\n",
        "\n",
        "      # optimizer.zero_grad() # Zero gradients\n",
        "      img, tiles_shuffl = img.to(DEVICE), tiles_shuffl.to(DEVICE)\n",
        "      labels = tile_list.to(DEVICE)\n",
        "\n",
        "      with torch.cuda.amp.autocast(): # This implements mixed precision. Thats it!\n",
        "          outputs = model(img, tiles_shuffl)\n",
        "          loss    = criterion(outputs, labels)\n",
        "\n",
        "      # print(outputs.shape)\n",
        "      # print('A')\n",
        "      # print(labels.shape)\n",
        "      # print(outputs)\n",
        "      # print('A')\n",
        "      # print(labels)\n",
        "      # print(sum((outputs - labels)**2))\n",
        "      # print((outputs - labels)**2)\n",
        "      # Update no. of correct predictions & loss as we iterate\n",
        "      # print(loss)\n",
        "\n",
        "      # print(torch.argmax(outputs, axis=1) )\n",
        "      # print('A')\n",
        "      # print(labels)\n",
        "      num_correct     += int((torch.argmax(outputs, axis=1) == labels).sum())\n",
        "      total_loss      += float(loss.item())\n",
        "\n",
        "      # tqdm lets you add some details so you can monitor training as you train.\n",
        "      batch_bar.set_postfix(\n",
        "            acc         = \"{:.04f}%\".format(100 * num_correct / (batch_size_train * (i + 1))),\n",
        "            loss        = \"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            num_correct = num_correct,\n",
        "          # tot_error = tot_error\n",
        "          # lr          = \"{:.04f}\".format(float(optimizer.param_groups[0]['lr']))\n",
        "      )\n",
        "\n",
        "      # scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "      # scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "      # scaler.update()\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # for param in model.parameters():\n",
        "      #   print(param.grad.data.sum())\n",
        "\n",
        "\n",
        "      batch_bar.update() # Update tqdm bar\n",
        "\n",
        "  batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "  acc         = 100 * num_correct / (batch_size_train * len(dataloader))\n",
        "  total_loss  = float(total_loss / len(dataloader))\n",
        "\n",
        "  return acc, total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "9Sh-rXAHosMH"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "Model1 = JigsawModel()\n",
        "optimizer = torch.optim.SGD(Model1.parameters(), lr=0.00001, momentum=0.9, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "umu8TKiGlNfm"
      },
      "outputs": [],
      "source": [
        "criterion_state = torch.nn.CrossEntropyLoss()\n",
        "Model_state = JigsawModel()\n",
        "optimizer_state = torch.optim.SGD(Model_state.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWX31kmkPKIc"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  train_state(Model_state, train_loader_state, criterion_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "alGbYxuOYI5l"
      },
      "outputs": [],
      "source": [
        "criterion_state = torch.nn.CrossEntropyLoss(reduction = 'sum', label_smoothing = 0.1)\n",
        "Model_state = JigsawModel_RN()\n",
        "optimizer_state = torch.optim.SGD(Model_state.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p98r4A-FYL7y"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "  train_state(Model_state, train_loader_state, criterion_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TkwPmu6jhpM_"
      },
      "outputs": [],
      "source": [
        "loss = torch.nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "print(output)\n",
        "output = loss(5*input, target)\n",
        "print(output)\n",
        "\n",
        "print(input, target)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IxQyWD50iZ6o",
        "EbSUEtvaiezt"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}