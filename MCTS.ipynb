{"cells":[{"cell_type":"markdown","metadata":{"id":"lTd5pHOAB8qx"},"source":["# Imports"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3302,"status":"ok","timestamp":1702410586520,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"Bn-xX-tPyRxA"},"outputs":[],"source":["import torchvision\n","import torch\n","import numpy as np\n","from collections import defaultdict\n","import torch.nn as nn\n","\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from torchsummary import summary\n","import tqdm\n","import random\n","import math"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702410586520,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"Y2I7nP0AyU19","outputId":"9cb2da5e-a5d2-42eb-d979-d1ce3b0084b5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Device:  cuda\n"]}],"source":["DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(\"Device: \", DEVICE)"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702410586520,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"c5f6LSGfyV9z"},"outputs":[],"source":["!unzip MNIST_CSV.zip"]},{"cell_type":"markdown","metadata":{"id":"ElkJmXCVB04X"},"source":["# Dataloading"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":9492,"status":"ok","timestamp":1702410596008,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"kHgq6zigyXIm"},"outputs":[],"source":["train_set = pd.read_csv(\"mnist_train.csv\")\n","test_images = pd.read_csv(\"mnist_test.csv\")\n","\n","train_images, val_images, train_labels, val_labels = train_test_split(train_set.iloc[:, 1:],\n","                                                                     train_set.iloc[:, 0],\n","                                                                     test_size=0.3)\n","\n","train_images.reset_index(drop=True, inplace=True)\n","val_images.reset_index(drop=True, inplace=True)\n","train_labels.reset_index(drop=True, inplace=True)\n","val_labels.reset_index(drop=True, inplace=True)\n","\n","train_images = train_images.to_numpy(dtype='float32')\n","train_labels = train_labels.to_numpy(dtype='float32')\n","\n","val_images = val_images.to_numpy()\n","val_labels = val_labels.to_numpy()\n","\n","test_images = test_images.to_numpy()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702410596009,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"AW-FWO8X0I8n"},"outputs":[],"source":["class JigsawDataset(torch.utils.data.Dataset):\n","    def __init__(self, images, labels, permutations=10, img_transformer=None):\n","        self.images = images\n","        self.labels = labels\n","        self.permutations = permutations\n","\n","        self.N = len(self.images)\n","        self.grid_size = 3\n","\n","    def __retrieve_permutations(self):\n","        nums = range(self.grid_size * self.grid_size)\n","\n","        return np.random.permutation(nums)\n","\n","    def __get_image(self, index):\n","        return self.images[index]\n","\n","    def __get_tiles(self, index):\n","        img = self.__get_image(index).reshape(28, 28)\n","        tiles = np.zeros((9, 9, 9), dtype='float32')\n","\n","        for i in range(3):\n","            for j in range(3):\n","                tiles[i * 3 + j] = img[i*9:i*9+9, j*9:j*9+9]\n","\n","        return tiles\n","\n","    def __getitem__(self, index):\n","        n_grids = self.grid_size ** 2\n","        tiles = self.__get_tiles(index)\n","\n","        order = self.__retrieve_permutations()\n","\n","        data = [torch.from_numpy(tiles[order[t]]) for t in range(n_grids)]\n","\n","        item = torch.stack(data, 0)\n","        return item, order, int(self.labels[index])\n","\n","    def __len__(self):\n","        return self.N"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702410596009,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"fl4Fcz-c0R3G"},"outputs":[],"source":["class JigsawDatasetTest(torch.utils.data.Dataset):\n","    def __init__(self, images, permutations=10, img_transformer=None):\n","        self.images = images\n","        self.permutations = permutations\n","\n","        self.N = len(self.images)\n","        self.grid_size = 3\n","\n","    def __retrieve_permutations(self):\n","        nums = range(self.grid_size * self.grid_size)\n","\n","        return np.random.permutation(nums)\n","\n","    def __get_image(self, index):\n","        return self.images[index]\n","\n","    def __get_tiles(self, index):\n","        img = self.__get_image(index).reshape(28, 28)\n","        tiles = np.zeros((9, 9, 9), dtype='float32')\n","\n","        for i in range(3):\n","            for j in range(3):\n","                tiles[i * 3 + j] = img[i*9:i*9+9, j*9:j*9+9]\n","\n","        return tiles\n","\n","    def __getitem__(self, index):\n","        n_grids = self.grid_size ** 2\n","        tiles = self.__get_tiles(index)\n","\n","        order = self.__retrieve_permutations()\n","        \n","        data = [torch.from_numpy(tiles[order[t]]) for t in range(n_grids)]\n","\n","        item = torch.stack(data, 0)\n","        return item, order\n","\n","    def __len__(self):\n","        return self.N"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1702410596009,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"dPSETLsD0Uac","outputId":"2ba318ae-9ce9-4c82-b4d9-471a8bab7347"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train dataset samples = 41999, batches = 41999\n","Val dataset samples = 18000, batches = 18000\n","Test dataset samples = 9999, batches = 9999\n"]}],"source":["train_data = JigsawDataset(train_images, train_labels)\n","val_data = JigsawDataset(val_images, val_labels)\n","test_data = JigsawDatasetTest(test_images)\n","\n","train_loader = torch.utils.data.DataLoader(\n","        dataset     = train_data,\n","        num_workers = 2,\n","        batch_size  = 1,\n","        pin_memory  = True,\n","        shuffle     = True,\n",")\n","\n","val_loader = torch.utils.data.DataLoader(\n","        dataset     = val_data,\n","        num_workers = 1,\n","        batch_size  = 1,\n","        pin_memory  = True,\n","        shuffle     = False,\n","    )\n","\n","test_loader = torch.utils.data.DataLoader(\n","        dataset     = test_data,\n","        num_workers = 1,\n","        batch_size  = 1,\n","        pin_memory  = True,\n","        shuffle     = False,\n","    )\n","\n","print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n","print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n","print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n"]},{"cell_type":"markdown","metadata":{"id":"Lmj_9FcNB46c"},"source":["# State and environment"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":204,"status":"ok","timestamp":1702410596196,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"Miyr-6C0SLJj"},"outputs":[],"source":["import sys\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","import matplotlib.pyplot as plt\n","\n","# Constants\n","GAMMA = 0.9\n","\n","class State:\n","    def __init__(self, tiles, current_shuffle_list, last_action=None):\n","        self.tiles = tiles\n","        self.current_shuffle_list = current_shuffle_list\n","        self.last_action = last_action\n","\n","        self.legal_actions = []\n","\n","        for i in range(8, 0, -1):\n","          for j in range(i):\n","            self.legal_actions.append((i,j))\n","\n","        num_incorrect = 9 - self.num_correct()\n","        print(f\"Initial incorrect: {num_incorrect}\")\n","\n","    def get_legal_actions(self):\n","        return self.legal_actions\n","\n","    def num_correct(self):\n","      count = 0\n","      for i in range(9):\n","        if i == self.current_shuffle_list[0][i]:\n","          count += 1\n","\n","      return count\n","\n","    def is_game_over(self):\n","        for i in range(9):\n","            if i != self.current_shuffle_list[0][i]:\n","                return False\n","\n","        return True\n","\n","    def move(self, action):\n","        i, j = action\n","        self.tiles[0][i], self.tiles[0][j] = self.tiles[0][j].clone(), self.tiles[0][i].clone()\n","\n","        self.current_shuffle_list[0][i], self.current_shuffle_list[0][j] = self.current_shuffle_list[0][j].item(), self.current_shuffle_list[0][i].item()\n","\n","        self.last_action = action\n","        return self"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702410596196,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"3kCqOrHc-GTs"},"outputs":[],"source":["class JigsawEnv():\n","\n","    def __init__(self, tiles, current_shuffle_list):\n","        self.state = State(tiles, current_shuffle_list)\n","        self.num_incorrect = 9 - self.state.num_correct()\n","\n","        self.actions = []\n","\n","        for i in range(8, 0, -1): # bc 0-8 is 9 numbers\n","          for j in range(i):\n","            self.actions.append((i,j))\n","\n","    \"\"\"\n","    Compute the reward for the current state of the environment.\n","\n","    Parameters:\n","    - None\n","\n","    Returns:\n","    - reward (float)\n","    \"\"\"\n","\n","    def computeReward(self):\n","        reward = 0\n","\n","        if self.state.is_game_over():\n","            reward += 100\n","        else:\n","            for i in range(9):\n","                if self.state.current_shuffle_list[0][i] == i:\n","                    reward += 1\n","\n","        return reward\n","\n","    \"\"\"\n","    Step the environment by one timestep.\n","\n","    Parameters:\n","    - action\n","\n","    Returns:\n","    - observation (object): agent's observation of the current environment\n","    - reward (float) : amount of reward returned after previous action\n","    - done (boolean): whether the episode has ended, in which case further step() calls will return undefined results\n","    - info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n","\n","    \"\"\"\n","    def step(self, action):\n","        observation = self.state.move(action)\n","        reward =  self.computeReward()\n","\n","        return observation, reward, self.state.is_game_over()\n","\n","    \"\"\"\n","    Renders the environment.\n","    \"\"\"\n","    def render(self):\n","        fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n","        fig.subplots_adjust(hspace=.1)\n","        for i in range(3):\n","            for j in range(3):\n","                ax[i][j].axis('off')\n","                ax[i][j].imshow(self.state.tiles[(self.state.order==i * 3 + j).nonzero(as_tuple=True)[0].item()], cmap='gray')"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702410596196,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"K9Zi-Sh0QFR3"},"outputs":[],"source":["\"\"\"\n","Global variable used to map policy network tensor to action tuple (i,j)\n","\"\"\"\n","\n","actions = []\n","\n","for i in range(8, 0, -1): # bc 0-8 is 9 numbers\n","  for j in range(i):\n","    actions.append((i,j))"]},{"cell_type":"markdown","metadata":{"id":"swl-M3V3Azod"},"source":["# Policy Network"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702410596196,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"xHnB-QGl-fqf"},"outputs":[],"source":["import torch.nn.functional as F\n","\n","class PolicyNetwork(nn.Module):\n","    def __init__(self, num_actions=36, lr=1e-3):\n","        super(PolicyNetwork, self).__init__()\n","\n","        self.num_actions = num_actions\n","        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n","        self.bn1 = nn.BatchNorm2d(16)\n","\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","\n","        self.conv3 = nn.Conv2d(32, 16, kernel_size=9, stride=9)\n","        self.bn3 = nn.BatchNorm2d(16)\n","\n","        self.linear1 = nn.Linear(144, 64)\n","        self.linear2 = nn.Linear(64, 36)\n","\n","        self.activation = nn.SiLU()\n","\n","        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n","\n","    def forward(self, state):\n","        out = self.assemble(state).to(DEVICE)\n","        out = self.conv1(out)\n","        out = self.bn1(out)\n","        out = self.activation(out)\n","\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.activation(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","        out = self.activation(out)\n","\n","        out = out.view(out.size(0), -1)\n","        out = self.linear1(out)\n","        out = self.activation(out)\n","\n","        out = self.linear2(out)\n","        out = F.softmax(out, dim=1)\n","        return out\n","\n","    \"\"\"\n","    Assembles 9x9x9 tensor into 1x27x27 tensor representing full image\n","\n","    Parameters:\n","    - state (tensor): state of the environment\n","\n","    Returns:\n","    - result_image (tensor): tensor representing full image\n","    \"\"\"\n","\n","    def assemble(self, state):\n","      num_batch = state.size(dim=0)\n","      result_image = torch.zeros(num_batch, 1, 27, 27)\n","\n","      for i in range(9):\n","          row = i // 3  # Calculate the row index in the 3x3 grid\n","          col = i % 3   # Calculate the column index in the 3x3 grid\n","\n","          # Calculate the starting position to place the image in the result tensor\n","          start_row = row * 9\n","          start_col = col * 9\n","\n","          # Assign the 9x9 image to the correct position in the result tensor\n","          result_image[:, :, start_row:start_row + 9, start_col:start_col + 9] = state[:, 3*row+col, :, :]\n","\n","      return result_image\n","\n","    \"\"\"\n","    Returns tensor of probabilities for each action\n","\n","    Parameters:\n","    - state (tensor): state of the environment\n","\n","    Returns:\n","    - probs (tensor): tensor of probabilities for each action\n","    \"\"\"\n","\n","    def get_action(self, state):\n","        probs = self.forward(Variable(state))\n","        probs = probs[0]\n","        probs = probs.cpu()\n","        return probs"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3358,"status":"ok","timestamp":1702410599550,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"6CUXkPzi-hdY","outputId":"c5dfb21f-3312-4357-bb77-9844e3ecb6f1"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["policy_network = PolicyNetwork().to(DEVICE)\n","dict1 = torch.load('FINAL.pth')\n","policy_network.load_state_dict(dict1['model_state_dict'])"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1702410599551,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"HsuTwIv4DgxO","outputId":"259363ee-42bd-4f03-e7f8-20ee4f7e8e3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["PARAMS: 66,228\n"]}],"source":["total_params = sum(\n","\tparam.numel() for param in policy_network.parameters()\n",")\n","print(f'PARAMS: {total_params:,}')\n"]},{"cell_type":"markdown","metadata":{"id":"kkS8f8zXA39C"},"source":["# Value Network"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1702410599551,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"TGI_h0X7A27W"},"outputs":[],"source":["class ValueNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","        self.resnet = torchvision.models.resnet18(pretrained=True)\n","        self.linear = nn.Linear(1000, 16)\n","        self.linear2 = nn.Linear(16, 1)\n","        self.softmax = nn.Softmax()\n","        self.flat = nn.Flatten()\n","\n","    def forward(self, x):\n","\n","        x = self.resnet(x)\n","        x = self.linear(x)\n","        x = self.linear2(x)\n","        # x = self.softmax(x)\n","        x = self.flat(x)\n","        x = torch.squeeze(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":594,"status":"ok","timestamp":1702410600131,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"f-oQhZQHBEDM","outputId":"008b8971-6f02-4bbb-c483-9ef62aa9ae43"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]},{"data":{"text/plain":["ValueNetwork(\n","  (resnet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (linear): Linear(in_features=1000, out_features=16, bias=True)\n","  (linear2): Linear(in_features=16, out_features=1, bias=True)\n","  (softmax): Softmax(dim=None)\n","  (flat): Flatten(start_dim=1, end_dim=-1)\n",")"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["from google.colab import drive\n","\n","value_network = ValueNetwork().to(DEVICE)\n","checkpoint = torch.load('/content/model_policy.pth')\n","value_network.load_state_dict(checkpoint['model_state_dict'])\n","value_network.eval()"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1702410600132,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"wiTIUgKvMkwQ","outputId":"390adcd7-dfd8-49d0-9b19-2ea32708e9b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["PARAMS: 11,705,545\n"]}],"source":["total_params = sum(\n","\tparam.numel() for param in value_network.parameters()\n",")\n","print(f'PARAMS: {total_params:,}')\n"]},{"cell_type":"markdown","metadata":{"id":"xteFkccABx32"},"source":["# MCTS"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702410600132,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"bOUiFF9dVdLw"},"outputs":[],"source":["policy_network.eval()\n","value_network.eval()\n","\n","from IPython.display import clear_output\n","clear_output()"]},{"cell_type":"code","execution_count":76,"metadata":{"executionInfo":{"elapsed":128,"status":"ok","timestamp":1702417390145,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"x6BEhIUWAndc"},"outputs":[],"source":["\"\"\"\n","TREE SEARCH VISUALIZATION\n","\"\"\"\n","\n","import networkx as nx\n","from networkx.drawing.nx_agraph import write_dot, graphviz_layout\n","import copy\n","\n","\n","def display_graph(tree):\n","    G = nx.DiGraph()\n","\n","    def add_edges(node):\n","        for child in node.children.values():\n","            if child.visits != 0:\n","              G.add_edge(node, child, label=(round(float(child.prior), 2), tuple(child.state.last_action)))\n","              add_edges(child)\n","\n","    add_edges(tree)\n","    write_dot(G,'test.dot')\n","\n","    # same layout using matplotlib with no labels\n","    pos =graphviz_layout(G, prog='dot')\n","    edge_labels = nx.get_edge_attributes(G, 'label')\n","    nx.draw(G, pos, with_labels=False, arrows=True, node_size=8)\n","    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_color='red', font_size=8)\n","\n","    plt.show()"]},{"cell_type":"code","execution_count":112,"metadata":{"executionInfo":{"elapsed":155,"status":"ok","timestamp":1702417703666,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"MJQ5jsA9W1Gj"},"outputs":[],"source":["def render(state):\n","    fig, ax = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n","    fig.subplots_adjust(hspace=.1)\n","    for i in range(3):\n","        for j in range(3):\n","            ax[i][j].axis('off')\n","            ax[i][j].imshow(state.tiles[0][i * 3 + j], cmap='gray')\n","\n","def simulate(node, value_network):\n","    \"\"\"\n","    Use value network to approximate the value of the state.\n","\n","    Alternatively, we can also using the policy net to perform a greedy search for a terminal state and backprop this estimated value.\n","    AlphaZero uses a mixing of random rollouts and estimation from their value network.\n","    \"\"\"\n","\n","    assembled = policy_network.assemble(node.state.tiles).to(DEVICE)\n","\n","    value = value_network(assembled.repeat(1,3,1,1))\n","\n","    transformed = math.exp(5 * (value - 0.65))\n","    return transformed *\n","\n","def custom_sort_key(children_with_values):\n","    return (children_with_values[1], children_with_values[0].prior)\n","\n"]},{"cell_type":"code","execution_count":122,"metadata":{"executionInfo":{"elapsed":256,"status":"ok","timestamp":1702417848452,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"xjRsHC33Sjdn"},"outputs":[],"source":["class TreeNode:\n","    def __init__(self, state, prior, policy_network=None, value_network=None, parent=None):\n","        self.state = state\n","        self.parent = parent\n","        self.children = {}\n","        self.visits = 0\n","        self.value_total = 0.0\n","        self.prior = prior\n","\n","        self.policy_network = policy_network\n","        self.value_network = value_network\n","\n","    def PUCT(self, child, exploration_weight):\n","        \"\"\"\n","        Inspired by AlphaGo, upper confidence bound for trees.\n","\n","\n","        PUCT = Q(s, a) + c * P(s, a) * sqrt(parent.vists) / (child.vists + 1)\n","\n","        Q(s, a) is zero when there have been no visits to that state-action pair.\n","        Otherwise Q(s, a) is the average reward from vists.\n","\n","        c is the exploration weight constant.\n","\n","        P(s, a) is the prior probablity given by the policy network.\n","        \"\"\"\n","\n","        prior_score = exploration_weight * child.prior * math.sqrt(self.visits) / (child.visits + 1)\n","\n","        if child.visits == 0:\n","          Q = 0\n","        else:\n","          Q = self.value_total / child.visits\n","        print(f\"Q:{Q}\")\n","        print(f\"prior_score{prior_score}\")\n","        return Q + prior_score\n","\n","\n","    def best_child(self, exploration_weight=1.0):\n","        \"\"\"\n","        Using PUCT with exploration_weight parameter.\n","\n","        We determine the action values from node statistics.\n","        We return the child with the highest action value.\n","        \"\"\"\n","        if not self.children:\n","            return None\n","\n","        children_with_values = [\n","            (child, self.PUCT(child, exploration_weight))\n","            for child in self.children.values()\n","        ]\n","\n","        # print(sorted(children_with_values, key=custom_sort_key))\n","        # print(f\"action values: {[float(value) for child, value in children_with_values]}\")\n","        return sorted(children_with_values, key=custom_sort_key)[0][0]\n","\n","\n","    def add_children(self):\n","        \"\"\"\n","        Add all children/edges/actions to the current node\n","        \"\"\"\n","        if len(self.children) == 0:\n","          self.policy = policy_network.get_action(self.state.tiles)\n","\n","          for i, prob in enumerate(self.policy):\n","            action = actions[i]\n","            next_state = copy.deepcopy(self.state).move(action)\n","\n","            child = TreeNode(next_state, prob, self.policy_network, self.value_network, parent=self)\n","            self.children[action] = child\n","\n","\n","    def expand_and_evaluate(self):\n","        \"\"\"\n","        Given an action, perform that action and expand the graph\n","        \"\"\"\n","        self.add_children()\n","        reward = simulate(self, self.value_network)\n","\n","        self.backpropagate(reward)\n","\n","    def print_node_statistics(self):\n","        for node in self.children.values():\n","          print(f\"Action: {node.state.last_action}, value: {node.value_total}, visits: {node.visits}, prior: {node.prior}\")\n","\n","    def most_visited_child(self):\n","        max = 0\n","        max_visited = None\n","        for child in self.children.values():\n","          if child.visits > max:\n","            max = child.visits\n","            max_visited = child\n","\n","        return max_visited\n","\n","    def depth(self):\n","        count = 0\n","        node = self\n","        while node is not None:\n","          count += 1\n","          node = node.parent\n","\n","        return count\n","\n","    def backpropagate(self, result):\n","        \"\"\"\n","        Backpropogate up the tree using the reward from the value network.\n","        Update node statistics.\n","        \"\"\"\n","\n","        node = self\n","        while node is not None:\n","            node.visits += 1\n","            node.value_total += result\n","            node = node.parent\n","\n","def mcts(root_node, policy_network=None, value_network=None, iterations=1000, exploration_weight=1.0):\n","    \"\"\"\n","    We perform the following for steps for some number of iterations.\n","    This function estimates the best action from the given root state.\n","\n","    1. Selection: choose node with highest action value\n","    2. Expansion: leaf node is expanded and policies are computed using the policy network\n","    3. Evaluation: using the value network to estimate the value of the state\n","    4. Backprop: we estimate the reward using the value network and update node statistics of all parents\n","    \"\"\"\n","\n","    root_node.add_children()\n","    root_node.visits = 1\n","\n","    for i in range(iterations):\n","        node = root_node\n","\n","        # DEBUG prints\n","        # print(f\"iteration {i}\")\n","        # node.print_node_statistics()\n","\n","        # Selection\n","        while node.children:\n","            node = node.best_child(exploration_weight)\n","\n","        # Expansion and Backpropgation (evaluation)\n","        node.expand_and_evaluate()\n","\n","        exploration_weight = max(0, exploration_weight * 0.99)\n","\n","    # display_graph(root_node)\n","    # Return most visited child\n","    best_child = root_node.most_visited_child()\n","    return best_child.state.last_action, best_child\n"]},{"cell_type":"code","execution_count":123,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":662,"status":"ok","timestamp":1702417849113,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"Z6FBTxe3bVi_","outputId":"389ac144-be2c-4c2f-bf3f-536e92db062c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Digit: tensor([2])\n"]}],"source":["tiles, order = None, None\n","for episode, (x, y, num) in enumerate(train_loader):\n","  tiles, order = x, y\n","\n","  print(f\"Digit: {num}\")\n","  break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702417849114,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"ogLurjWG45xl","outputId":"a9458ad0-bbbc-427e-bfbd-62dab532022b"},"outputs":[],"source":["env = JigsawEnv(tiles, order)\n","simulate(env.state, value_network)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":180785,"status":"ok","timestamp":1702418029896,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"Y0KwTv7QUWeb","outputId":"d9ed9dd0-994b-425a-9cd8-1cbe59872826"},"outputs":[],"source":["print(f\"Initial state: {env.state.current_shuffle_list}\")\n","root_node = TreeNode(env.state, 0.0, policy_network, value_network)\n","\n","print(f\"Policy greedy recommendation: {actions[np.argmax(policy_network.get_action(env.state.tiles).detach().numpy())]}\")\n","\n","best_action, _ = mcts(root_node, policy_network, value_network, iterations=100, exploration_weight=100)\n","print(f\"MCTS recommends: {best_action}\")\n","\n","root_node.print_node_statistics()\n","\n","print(f\"Initial state: {env.state.current_shuffle_list}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1702417707456,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"1QTfUS9ycxpt","outputId":"212e8201-2f39-4de9-8c83-5519188d5ccd"},"outputs":[],"source":["root_node.children[(5,4)].print_node_statistics()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702410604961,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"D08DIFiuUHsL"},"outputs":[],"source":["def solve(env, policy_network, value_network, iterations=50, exploration_weight=1.0):\n","    \"\"\"\n","    Solves the environment using MCTS.\n","\n","    Parameters:\n","    - env: environment\n","    - policy_network: policy network\n","    - value_network: value network\n","    - iterations: number of iterations to run MCTS\n","    - exploration_weight: exploration weight\n","\n","    Returns:\n","    - actions: list of actions to solve the environment\n","    - state: final state\n","    \"\"\"\n","    root_node = TreeNode(env.state, 0, policy_network, value_network)\n","\n","    confidence = 0\n","\n","    iter = 0\n","    max_swaps = 25\n","\n","    while confidence < 0.85 and iter < max_swaps:\n","        best_action, root_node = mcts(root_node, policy_network, value_network, iterations=iterations, exploration_weight=exploration_weight)\n","\n","        confidence = value_network(policy_network.assemble(root_node.state.tiles).to(DEVICE).repeat(1, 3, 1, 1))\n","\n","        iter += 1\n","\n","    return root_node.state, iter\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702410604961,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"m8B6RX1tTjD7"},"outputs":[],"source":["def is_success(final_state):\n","    \"\"\"\n","    Checks if the final state is the goal state.\n","\n","    ***\n","    If tiles are identitical, we disregard if they in the \"wrong\" position\n","    ***\n","\n","    Parameters:\n","    - env: environment\n","    - final_state: final state\n","\n","    Returns:\n","    - success: True if the final state is the goal state, False otherwise\n","    \"\"\"\n","\n","    for i in range(9):\n","        if i != final_state.current_shuffle_list[0][i]:\n","            if torch.all(final_state.tiles[0][i] == 0):\n","                continue\n","            else:\n","                return False\n","\n","    return True\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1,"status":"aborted","timestamp":1702410604961,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"lr_gYFcIAfRS"},"outputs":[],"source":["def solve2(env, policy_network, value_network, iterations=50, exploration_weight=1.0):\n","    \"\"\"\n","    Solves the environment using MCTS.\n","\n","    Parameters:\n","    - env: environment\n","    - policy_network: policy network\n","    - value_network: value network\n","    - iterations: number of iterations to run MCTS\n","    - exploration_weight: exploration weight\n","\n","    Returns:\n","    - actions: list of actions to solve the environment\n","    - state: final state\n","    \"\"\"\n","    state = env.state\n","    root_node = TreeNode(state, 0, policy_network, value_network)\n","\n","    confidence = 0\n","\n","    iter = 0\n","    max_swaps = 25\n","\n","    while not is_success(state) and iter < 50:\n","        best_action, root_node = mcts(root_node, policy_network, value_network, iterations=iterations, exploration_weight=exploration_weight)\n","        state = root_node.state\n","\n","        # confidence = value_network(policy_network.assemble(root_node.state.tiles).to(DEVICE).repeat(1, 3, 1, 1))\n","        iter += 1\n","\n","    return root_node.state, iter\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1702410605169,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"5ldMWT44Jiis"},"outputs":[],"source":["\"\"\"\n","TEST!\n","\n","Solving boards to completion using MCTS\n","\"\"\"\n","success = 0\n","steps = 0\n","\n","for episode, (x, y, num) in enumerate(val_loader):\n","  tiles, order = x, y\n","\n","  env = JigsawEnv(tiles, order)\n","  state, swaps = solve2(env, policy_network, value_network, iterations=100, exploration_weight=1)\n","\n","  if is_success(state):\n","    success += 1\n","    steps += swaps\n","    print(f\"Success in {swaps} steps!\")\n","  else:\n","    print(\"Failed :(\")\n","\n","  render(state)\n","\n","print(f\"Percent success: {success / len(val_loader) * 100}%\")\n","print(f\"Average swaps on success: {steps / len(val_loader) * 100}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":3,"status":"aborted","timestamp":1702410605169,"user":{"displayName":"Lawrence","userId":"11704523392480950822"},"user_tz":300},"id":"IfFYuiUcE-DZ"},"outputs":[],"source":["print(success/episode)"]}],"metadata":{"colab":{"collapsed_sections":["lTd5pHOAB8qx","ElkJmXCVB04X","swl-M3V3Azod","kkS8f8zXA39C"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
